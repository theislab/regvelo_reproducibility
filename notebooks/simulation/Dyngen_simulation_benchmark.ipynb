{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a72b96-89b4-4be5-9522-cacc478b83ff",
   "metadata": {},
   "source": [
    "# Perform benchmark on dyngen simulated datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15751672-47a9-482a-9a98-ca774369a028",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e083d418-2d7f-4656-aa05-f6157b3a99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from typing import Literal\n",
    "\n",
    "import velovae as vv\n",
    "from distributed import Client, LocalCluster\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "import mplscience\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "\n",
    "## define function\n",
    "import torch\n",
    "import unitvelo as utv\n",
    "from arboreto.algo import grnboost2\n",
    "from regvelo import REGVELOVI\n",
    "from velovi import preprocess_data, VELOVI\n",
    "\n",
    "from rgv_tools import DATA_DIR, FIG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569576d5-6849-4fce-aeba-fa20003ae4f0",
   "metadata": {},
   "source": [
    "## General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ae4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.getcwd() + \"/RegVelo_datasets/VeloVAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c031bfba-a157-4433-98b4-9aaef06a9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_defaults()\n",
    "sns.reset_orig()\n",
    "scv.settings.set_figure_params(\"scvelo\", dpi_save=400, dpi=80, transparent=True, fontsize=14, color_map=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08fc0dfc-01c6-4d15-addf-c170f1a8e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"svg.fonttype\"] = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210a4836-8d85-4d92-bba2-7b171fb11334",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "SAVE_FIGURES = True\n",
    "if SAVE_FIGURES:\n",
    "    (FIG_DIR / \"simulation\" / \"dyngen_results\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAVE_DATASETS = True\n",
    "if SAVE_DATASETS:\n",
    "    (DATA_DIR / \"simulation\" / \"dyngen_results\").mkdir(parents=True, exist_ok=True)\n",
    "    (DATA_DIR / \"simulation\" / \"dyngen_results\" / \"copy_file\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f656db05-9ecd-42fb-9177-8205848bd70c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe78ef5c-2a21-4d55-9f23-0995a9400360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csgn_groundtruth(adata):\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    csgn_array = adata.obsm[\"regulatory_network_sc\"].toarray()\n",
    "    csgn_tensor = torch.zeros([len(adata.uns[\"regulators\"]), len(adata.uns[\"targets\"]), csgn_array.shape[0]])\n",
    "\n",
    "    for k in range(csgn_array.shape[0]):\n",
    "        ## generate a 3D tensor to indicate the ground truth network for each cell\n",
    "        grnboost_m = np.zeros((len(adata.uns[\"regulators\"]), len(adata.uns[\"targets\"])))\n",
    "        grnboost_m = pd.DataFrame(grnboost_m, index=adata.uns[\"regulators\"], columns=adata.uns[\"targets\"])\n",
    "        for i in range(adata.uns[\"regulatory_network\"].shape[0]):\n",
    "            # ind = (adata.uns[\"regulatory_network\"][\"regulator\"] == j) & (adata.uns[\"regulatory_network\"][\"target\"] == i)\n",
    "            regulator = adata.uns[\"regulatory_network\"].iloc[i][\"regulator\"]\n",
    "            target = adata.uns[\"regulatory_network\"].iloc[i][\"target\"]\n",
    "            grnboost_m.loc[regulator, target] = csgn_array[k, i]\n",
    "        tensor = torch.tensor(np.array(grnboost_m))\n",
    "        csgn_tensor[:, :, k] = tensor\n",
    "\n",
    "    return csgn_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csgn_benchmark(GRN, csgn):\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    csgn[csgn != 0] = 1\n",
    "    if len(GRN.shape) > 2:\n",
    "        print(\"Input is cell type specific GRN...\")\n",
    "        score = []\n",
    "        for i in range(csgn.shape[2]):\n",
    "            W = csgn[:, :, i]\n",
    "            W[W != 0] = 1\n",
    "            # auprc = sklearn.metrics.average_precision_score(W.T.ravel(), np.abs(GRN[:,:,i].numpy().ravel()))\n",
    "            fpr, tpr, thresholds = sklearn.metrics.roc_curve(\n",
    "                y_true=W.T.ravel(), y_score=GRN[:, :, i].numpy().ravel(), pos_label=1\n",
    "            )  # positive class is 1; negative class is 0\n",
    "            auroc = sklearn.metrics.auc(fpr, tpr)\n",
    "            score.append(auroc)\n",
    "    else:\n",
    "        print(\"Input is global GRN...\")\n",
    "        score = []\n",
    "        for i in range(csgn.shape[2]):\n",
    "            W = csgn[:, :, i]\n",
    "            W[W != 0] = 1\n",
    "            # auprc = sklearn.metrics.average_precision_score(W.T.ravel(), np.abs(GRN.numpy().ravel()))\n",
    "            fpr, tpr, thresholds = sklearn.metrics.roc_curve(\n",
    "                y_true=W.T.ravel(), y_score=GRN.numpy().ravel(), pos_label=1\n",
    "            )  # positive class is 1; negative class is 0\n",
    "            auroc = sklearn.metrics.auc(fpr, tpr)\n",
    "            score.append(auroc)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90642c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csgn_benchmark2(GRN, W, csgn):\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    csgn[csgn != 0] = 1\n",
    "    if len(GRN.shape) > 2:\n",
    "        print(\"Input is cell type specific GRN...\")\n",
    "        score = []\n",
    "        for i in range(csgn.shape[2]):\n",
    "            net = csgn[:, :, i]\n",
    "            # auprc = sklearn.metrics.average_precision_score(W.T.ravel(), np.abs(GRN[:,:,i].numpy().ravel()))\n",
    "            pre = GRN[:, :, i][np.array(W.T) == 1]\n",
    "            gt = net.T[np.array(W.T) == 1]\n",
    "            gt[gt != 0] = 1\n",
    "\n",
    "            number = min(10000, len(gt))\n",
    "            pre, index = torch.topk(pre, number)\n",
    "            fpr, tpr, thresholds = sklearn.metrics.roc_curve(\n",
    "                y_true=gt[index], y_score=pre, pos_label=1\n",
    "            )  # positive class is 1; negative class is 0\n",
    "            auroc = sklearn.metrics.auc(fpr, tpr)\n",
    "            score.append(auroc)\n",
    "    else:\n",
    "        print(\"Input is global GRN...\")\n",
    "        score = []\n",
    "        for i in range(csgn.shape[2]):\n",
    "            net = csgn[:, :, i]\n",
    "            pre = GRN[np.array(W.T) == 1]\n",
    "            gt = net.T[np.array(W.T) == 1]\n",
    "            gt[gt != 0] = 1\n",
    "\n",
    "            number = min(10000, len(gt))\n",
    "            pre, index = torch.topk(pre, number)\n",
    "            fpr, tpr, thresholds = sklearn.metrics.roc_curve(\n",
    "                y_true=gt[index], y_score=pre, pos_label=1\n",
    "            )  # positive class is 1; negative class is 0\n",
    "            auroc = sklearn.metrics.auc(fpr, tpr)\n",
    "            score.append(auroc)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54fdbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(\n",
    "    adata,\n",
    "    network_mode: Literal[\"GENIE3\", \"full_ODE\"] = \"GENIE3\",\n",
    ") -> anndata.AnnData:\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    if network_mode == \"GENIE3\":\n",
    "        reg_index = [i in adata.var.index.values for i in adata.uns[\"regulators\"]]\n",
    "        tar_index = [i in adata.var.index.values for i in adata.uns[\"targets\"]]\n",
    "        adata.uns[\"regulators\"] = adata.uns[\"regulators\"][reg_index]\n",
    "        adata.uns[\"targets\"] = adata.uns[\"targets\"][tar_index]\n",
    "        W = adata.uns[\"skeleton\"]\n",
    "        W = W[reg_index, :]\n",
    "        W = W[:, tar_index]\n",
    "        adata.uns[\"skeleton\"] = W\n",
    "        W = adata.uns[\"network\"]\n",
    "        W = W[reg_index, :]\n",
    "        W = W[:, tar_index]\n",
    "        adata.uns[\"network\"] = W\n",
    "        regulators = adata.uns[\"regulators\"][adata.uns[\"skeleton\"].sum(1) > 0]\n",
    "        targets = adata.uns[\"targets\"][adata.uns[\"skeleton\"].sum(0) > 0]\n",
    "        adata = adata[:, np.unique(regulators.tolist() + targets.tolist())].copy()\n",
    "        ## to make sure consistency\n",
    "        regulator_index = [i in regulators for i in adata.var.index.values]\n",
    "        target_index = [i in targets for i in adata.var.index.values]\n",
    "        regulators = adata.var.index.values[regulator_index]\n",
    "        targets = adata.var.index.values[target_index]\n",
    "        print(\"num regulators: \" + str(len(regulators)))\n",
    "        print(\"num targets: \" + str(len(targets)))\n",
    "        W = pd.DataFrame(adata.uns[\"skeleton\"], index=adata.uns[\"regulators\"], columns=adata.uns[\"targets\"])\n",
    "        W = W.loc[regulators, targets]\n",
    "        adata.uns[\"skeleton\"] = W\n",
    "        W = pd.DataFrame(adata.uns[\"network\"], index=adata.uns[\"regulators\"], columns=adata.uns[\"targets\"])\n",
    "        W = W.loc[regulators, targets]\n",
    "        adata.uns[\"network\"] = W\n",
    "        adata.uns[\"regulators\"] = regulators\n",
    "        adata.uns[\"targets\"] = targets\n",
    "    if network_mode == \"full_ODE\":\n",
    "        ## filter the gene first\n",
    "        csgn = adata.uns[\"csgn\"]\n",
    "        gene_name = adata.var.index.tolist()\n",
    "        full_name = adata.uns[\"regulators\"]\n",
    "        index = [i in gene_name for i in full_name]\n",
    "        full_name = full_name[index]\n",
    "        adata = adata[:, full_name].copy()\n",
    "        W = adata.uns[\"skeleton\"]\n",
    "        W = W[index, :]\n",
    "        W = W[:, index]\n",
    "        adata.uns[\"skeleton\"] = W\n",
    "        W = adata.uns[\"network\"]\n",
    "        W = W[index, :]\n",
    "        W = W[:, index]\n",
    "        csgn = csgn[index, :, :]\n",
    "        csgn = csgn[:, index, :]\n",
    "        adata.uns[\"network\"] = W\n",
    "        ###\n",
    "        W = adata.uns[\"skeleton\"]\n",
    "        gene_name = adata.var.index.tolist()\n",
    "        indicator = W.sum(0) > 0  ## every gene would need to have a upstream regulators\n",
    "        regulators = [gene for gene, boolean in zip(gene_name, indicator) if boolean]\n",
    "        targets = [gene for gene, boolean in zip(gene_name, indicator) if boolean]\n",
    "        print(\"num regulators: \" + str(len(regulators)))\n",
    "        print(\"num targets: \" + str(len(targets)))\n",
    "        W = adata.uns[\"skeleton\"]\n",
    "        W = W[indicator, :]\n",
    "        W = W[:, indicator]\n",
    "        adata.uns[\"skeleton\"] = W\n",
    "        W = adata.uns[\"network\"]\n",
    "        W = W[indicator, :]\n",
    "        W = W[:, indicator]\n",
    "        adata.uns[\"network\"] = W\n",
    "        csgn = csgn[indicator, :, :]\n",
    "        csgn = csgn[:, indicator, :]\n",
    "        adata.uns[\"csgn\"] = csgn\n",
    "        adata.uns[\"regulators\"] = regulators\n",
    "        adata.uns[\"targets\"] = targets\n",
    "        W = pd.DataFrame(adata.uns[\"skeleton\"], index=adata.uns[\"regulators\"], columns=adata.uns[\"targets\"])\n",
    "        W = W.loc[regulators, targets]\n",
    "        adata.uns[\"skeleton\"] = W\n",
    "        W = pd.DataFrame(adata.uns[\"network\"], index=adata.uns[\"regulators\"], columns=adata.uns[\"targets\"])\n",
    "        W = W.loc[regulators, targets]\n",
    "        adata.uns[\"network\"] = W\n",
    "        adata = adata[:, indicator].copy()\n",
    "        adata.obsm[\"knn\"] = adata.uns[\"neighbors\"][\"indices\"].copy()\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4693feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_velovi_outputs_to_adata(adata, vae):\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    latent_time = vae.get_latent_time(n_samples=25)\n",
    "    velocities = vae.get_velocity(n_samples=25, velo_statistic=\"mean\")\n",
    "    t = latent_time\n",
    "    scaling = 20 / t.max(0)\n",
    "    adata.layers[\"velocity\"] = velocities / scaling\n",
    "    adata.layers[\"latent_time_velovi\"] = latent_time\n",
    "    adata.var[\"fit_alpha\"] = vae.get_rates()[\"alpha\"] / scaling\n",
    "    adata.var[\"fit_beta\"] = vae.get_rates()[\"beta\"] / scaling\n",
    "    adata.var[\"fit_gamma\"] = vae.get_rates()[\"gamma\"] / scaling\n",
    "    adata.var[\"fit_t_\"] = (\n",
    "        torch.nn.functional.softplus(vae.module.switch_time_unconstr).detach().cpu().numpy()\n",
    "    ) * scaling\n",
    "    adata.layers[\"fit_t_velovi\"] = latent_time.values * scaling[np.newaxis, :]\n",
    "    adata.var[\"fit_scaling\"] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450510f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_graph(W, noise_level=0.2):\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    W_c = 1 - W\n",
    "    edge = torch.nonzero(W)\n",
    "    ## drop edge\n",
    "    num_edge = edge.shape[0]\n",
    "    selected_numbers = random.sample(range(edge.shape[0]), math.ceil((1 - noise_level) * num_edge))\n",
    "    edge = edge[selected_numbers, :]\n",
    "    #\n",
    "    edge_c = torch.nonzero(W_c)\n",
    "    ## select noise edge\n",
    "    selected_numbers = random.sample(range(edge_c.shape[0]), math.ceil((noise_level) * num_edge))\n",
    "    edge_c = edge_c[selected_numbers, :]\n",
    "    ### generate final edge\n",
    "    edge = torch.cat([edge, edge_c], 0)\n",
    "    ## generate disturbed graph\n",
    "    binary_tensor = torch.zeros(W.shape)\n",
    "    binary_tensor[edge[:, 0], edge[:, 1]] = 1\n",
    "    return binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_regvelo_outputs_to_adata(adata_raw, vae):\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    latent_time = vae.get_latent_time(n_samples=25)\n",
    "    velocities = vae.get_velocity(n_samples=25)\n",
    "\n",
    "    t = latent_time\n",
    "    scaling = 20 / t.max(0)\n",
    "    adata = adata_raw[:, vae.module.target_index].copy()\n",
    "\n",
    "    adata.layers[\"velocity\"] = velocities / scaling\n",
    "    # adata.layers[\"velocity\"] = velocities\n",
    "    adata.layers[\"latent_time_regvelo\"] = latent_time\n",
    "\n",
    "    adata.layers[\"fit_t\"] = latent_time.values * scaling[np.newaxis, :]\n",
    "    # adata.layers[\"fit_t\"] = latent_time.values\n",
    "    adata.var[\"fit_scaling\"] = 1.0\n",
    "\n",
    "    # adata.obs[\"latent_time\"] = vae.compute_shared_time(adata.layers[\"fit_t\"])\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5221a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRN_Jacobian(reg_vae, Ms):\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    reg_vae.module.v_encoder.fc1.weight.detach()\n",
    "    reg_vae.module.v_encoder.fc1.bias.detach()\n",
    "    reg_vae.module.v_encoder.alpha_unconstr_max.detach()\n",
    "    ## calculate the jacobian matrix respect to each cell\n",
    "    Jaco_m = []\n",
    "    for i in range(Ms.shape[0]):\n",
    "        s = Ms[i, :]\n",
    "        ## calculate sigmoid probability\n",
    "        # alpha_unconstr = torch.matmul(net,torch.tensor(s[reg_vae.module.v_encoder.regulator_index]))\n",
    "        # alpha_unconstr = alpha_unconstr + bias\n",
    "        # alpha_unconstr = reg_vae.module.v_encoder.fc1(torch.tensor(s[reg_vae.module.v_encoder.regulator_index]).to(\"cuda:0\")).detach()\n",
    "        # coef = (F.sigmoid(alpha_unconstr))\n",
    "        # alpha_max = torch.clamp(F.softplus(max_rate),0,50)\n",
    "        # Jaco_m.append(torch.matmul(torch.diag(coef), net))\n",
    "        Jaco_m.append(\n",
    "            reg_vae.module.v_encoder.GRN_Jacobian(\n",
    "                torch.tensor(s[reg_vae.module.v_encoder.regulator_index]).to(\"cuda:0\")\n",
    "            ).detach()\n",
    "        )\n",
    "    Jaco_m = torch.stack(Jaco_m, 2)\n",
    "    return Jaco_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287686e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sign_ratio(vector1, vector2):\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    if len(vector1) != len(vector2):\n",
    "        raise ValueError(\"Both vectors must have the same length.\")\n",
    "    same_sign_count = 0\n",
    "    total_count = 0\n",
    "    for sign1, sign2 in zip(vector1, vector2):\n",
    "        if sign1 != 0 and sign2 != 0:\n",
    "            if sign1 == sign2:\n",
    "                same_sign_count += 1\n",
    "            total_count += 1\n",
    "    if total_count == 0:\n",
    "        return 0.0\n",
    "    return same_sign_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a934430a-ee3b-4ec5-8a0a-e56c64089085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significance(pvalue):\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    if pvalue < 0.001:\n",
    "        return \"***\"\n",
    "    elif pvalue < 0.01:\n",
    "        return \"**\"\n",
    "    elif pvalue < 0.1:\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"n.s.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a90af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_significance2(ax, bottom: int, top: int, significance: str, level: int = 0, **kwargs):\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    bracket_level = kwargs.pop(\"bracket_level\", 1)\n",
    "    bracket_height = kwargs.pop(\"bracket_height\", 0.02)\n",
    "    text_height = kwargs.pop(\"text_height\", 0.01)\n",
    "\n",
    "    left, right = ax.get_xlim()\n",
    "    x_axis_range = right - left\n",
    "\n",
    "    bracket_level = (x_axis_range * 0.07 * level) + right * bracket_level\n",
    "    bracket_height = bracket_level - (x_axis_range * bracket_height)\n",
    "\n",
    "    ax.plot([bracket_height, bracket_level, bracket_level, bracket_height], [bottom, bottom, top, top], **kwargs)\n",
    "\n",
    "    ax.text(\n",
    "        bracket_level + (x_axis_range * text_height),\n",
    "        (bottom + top) * 0.5,\n",
    "        significance,\n",
    "        va=\"center\",\n",
    "        ha=\"left\",\n",
    "        c=\"k\",\n",
    "        rotation=90,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a38e8-cac6-4647-a0db-2b830e1d20b6",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e83ba5-664c-4a2c-9440-142be62652da",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = [file for file in (DATA_DIR / \"dyngen\").iterdir() if file.endswith(\".h5ad\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84df7af6-26cd-4bcd-b03b-020e2150a1b7",
   "metadata": {},
   "source": [
    "## Running Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_time_corr_all = []\n",
    "gene_velo_corr_all = []\n",
    "AUC_GRN_result = []\n",
    "AUC_GRN_result_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8114251a-7459-4907-bc40-97c39608aa55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for adata_name in adatas:\n",
    "    address = os.getcwd() + \"/RegVelo_datasets/dyngen_simulation/\" + adata_name\n",
    "\n",
    "    adata = sc.read_h5ad(address)\n",
    "    adata_raw = adata.copy()\n",
    "    csgn = csgn_groundtruth(adata)\n",
    "    adata.uns[\"csgn\"] = csgn\n",
    "\n",
    "    adata.X = adata.X.copy()\n",
    "    adata.layers[\"spliced\"] = adata.layers[\"counts_spliced\"].copy()\n",
    "    adata.layers[\"unspliced\"] = adata.layers[\"counts_unspliced\"].copy()\n",
    "\n",
    "    scv.pp.filter_and_normalize(adata, min_shared_counts=10)\n",
    "    sc.tl.pca(adata)\n",
    "    sc.pp.neighbors(adata, n_neighbors=30, n_pcs=30)\n",
    "    scv.pp.moments(adata)\n",
    "    # scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
    "\n",
    "    adata.X = np.log1p(adata.X.copy())\n",
    "\n",
    "    sc.tl.leiden(adata)\n",
    "    adata_raw.obs[\"cluster\"] = adata.obs[\"leiden\"].copy()\n",
    "    adata_raw.obsm[\"X_pca\"] = adata.obsm[\"X_pca\"].copy()\n",
    "    adata_raw.layers[\"spliced\"] = adata_raw.layers[\"counts_spliced\"].copy()\n",
    "    adata_raw.layers[\"unspliced\"] = adata_raw.layers[\"counts_unspliced\"].copy()\n",
    "\n",
    "    adata = preprocess_data(adata, filter_on_r2=True)\n",
    "    adata = sanity_check(adata, network_mode=\"full_ODE\")\n",
    "    adata.uns[\"Ms\"] = adata.layers[\"Ms\"]\n",
    "    adata.uns[\"Mu\"] = adata.layers[\"Mu\"]\n",
    "\n",
    "    ## save raw data\n",
    "    adata_raw.var[\"highly_variable\"] = [adata_raw.var.index[i] in adata.var.index for i in range(adata_raw.shape[1])]\n",
    "    adata_raw = adata_raw[:, adata_raw.var[\"highly_variable\"]]\n",
    "    save_address = \"data_file_\" + adata_name\n",
    "    save_address = DATA_DIR / \"simulation\" / \"dyngen_results\" / \"copy_file\" / save_address\n",
    "    adata_raw.write(save_address)\n",
    "\n",
    "    ## Run scVelo model (dynamical)\n",
    "    scv.tl.recover_dynamics(adata, fit_scaling=False, var_names=adata.var_names, n_jobs=1)\n",
    "    adata.var[\"fit_scaling\"] = 1.0\n",
    "    adata.layers[\"fit_t_dynamical\"] = adata.layers[\"fit_t\"].copy()\n",
    "    scv.tl.velocity(adata, mode=\"dynamical\", min_likelihood=-np.inf, min_r2=None)\n",
    "    scv.tl.latent_time(adata, min_likelihood=None)\n",
    "\n",
    "    velocity_gt = adata.layers[\"rna_velocity\"]\n",
    "    velocity = adata.layers[\"velocity\"]\n",
    "    dim = velocity.shape[1]\n",
    "\n",
    "    corr = []\n",
    "    for i in range(velocity.shape[1]):\n",
    "        corr.append(\n",
    "            scipy.stats.pearsonr(np.array(velocity_gt.todense()[:, i]).ravel(), np.array(velocity[:, i]).ravel())\n",
    "        )\n",
    "\n",
    "    corr = np.array(corr)[:, 0]\n",
    "    dynamical_corr = corr\n",
    "\n",
    "    ## Run scVelo model (stochastic)\n",
    "    scv.tl.velocity(adata, mode=\"stochastic\")\n",
    "    velocity_gt = adata.layers[\"rna_velocity\"]\n",
    "    velocity = adata.layers[\"velocity\"]\n",
    "    dim = velocity.shape[1]\n",
    "\n",
    "    corr = []\n",
    "    for i in range(velocity.shape[1]):\n",
    "        corr.append(\n",
    "            scipy.stats.pearsonr(np.array(velocity_gt.todense()[:, i]).ravel(), np.array(velocity[:, i]).ravel())\n",
    "        )\n",
    "\n",
    "    corr = np.array(corr)[:, 0]\n",
    "    stochastic_corr = corr\n",
    "\n",
    "    ## Run scVelo model (deterministic)\n",
    "    scv.tl.velocity(adata, mode=\"deterministic\")\n",
    "    velocity_gt = adata.layers[\"rna_velocity\"]\n",
    "    velocity = adata.layers[\"velocity\"]\n",
    "    dim = velocity.shape[1]\n",
    "\n",
    "    corr = []\n",
    "    for i in range(velocity.shape[1]):\n",
    "        corr.append(\n",
    "            scipy.stats.pearsonr(np.array(velocity_gt.todense()[:, i]).ravel(), np.array(velocity[:, i]).ravel())\n",
    "        )\n",
    "\n",
    "    corr = np.array(corr)[:, 0]\n",
    "    deterministic_corr = corr\n",
    "\n",
    "    ### fit VeloVI\n",
    "    torch.cuda.empty_cache()\n",
    "    VELOVI.setup_anndata(adata, spliced_layer=\"Ms\", unspliced_layer=\"Mu\")\n",
    "    vae = VELOVI(adata)\n",
    "    vae.train()\n",
    "    add_velovi_outputs_to_adata(adata, vae)\n",
    "\n",
    "    velocity_gt = adata.layers[\"rna_velocity\"]\n",
    "    velocity = adata.layers[\"velocity\"]\n",
    "    corr = []\n",
    "    for i in range(velocity.shape[1]):\n",
    "        corr.append(\n",
    "            scipy.stats.pearsonr(np.array(velocity_gt.todense()[:, i]).ravel(), np.array(velocity[:, i]).ravel())\n",
    "        )\n",
    "        # corr.append(get_sign_ratio(np.sign(np.array(velocity_gt.todense()[:,i]).ravel()), np.sign(np.array(velocity[:,i]).ravel())))\n",
    "\n",
    "    corr = np.array(corr)[:, 0]\n",
    "    velovi_corr = corr\n",
    "\n",
    "    ### Run RegVelo\n",
    "    W = adata.uns[\"skeleton\"].copy()\n",
    "    GRN_gt = adata.uns[\"skeleton\"].copy()\n",
    "    W = torch.tensor(np.array(W)).int()\n",
    "    W = torch.ones(W.shape)\n",
    "\n",
    "    \"\"\"\n",
    "    intersection = list(set(adata.uns[\"regulators\"]).intersection(adata.uns[\"targets\"]))\n",
    "    for i in intersection:\n",
    "        index1 = [j == i for j in adata.uns[\"regulators\"]]\n",
    "        index2 = [j == i for j in adata.uns[\"targets\"]]\n",
    "        W[index1,index2] = 0\n",
    "    \"\"\"\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    REGVELOVI.setup_anndata(adata, spliced_layer=\"Ms\", unspliced_layer=\"Mu\")\n",
    "    reg_vae = REGVELOVI(adata, W=W, t_max=20)\n",
    "    reg_vae.train()\n",
    "\n",
    "    adata_target = add_regvelo_outputs_to_adata(adata, reg_vae)\n",
    "\n",
    "    velocity_gt = adata_target.layers[\"rna_velocity\"]\n",
    "    velocity = adata_target.layers[\"velocity\"]\n",
    "    corr = []\n",
    "    for i in range(velocity.shape[1]):\n",
    "        corr.append(\n",
    "            scipy.stats.pearsonr(np.array(velocity_gt.todense()[:, i]).ravel(), np.array(velocity[:, i]).ravel())\n",
    "        )\n",
    "        # corr.append(get_sign_ratio(np.sign(np.array(velocity_gt.todense()[:,i]).ravel()), np.sign(np.array(velocity[:,i]).ravel())))\n",
    "\n",
    "    corr = np.array(corr)[:, 0]\n",
    "    regvelo_corr = corr\n",
    "\n",
    "    Jaco_m = GRN_Jacobian(reg_vae, adata.layers[\"Ms\"])\n",
    "\n",
    "    # calculate unitvelo\n",
    "    velo = utv.config.Configuration()\n",
    "    velo.GPU = -1\n",
    "    velo.FIT_OPTION = \"1\"\n",
    "    adata_utv = utv.run_model(str(save_address), \"cluster\", config_file=velo)\n",
    "\n",
    "    dim = adata.shape[1]\n",
    "    velocity_gt = adata_utv.layers[\"rna_velocity\"]\n",
    "    velocity = adata_utv.layers[\"velocity\"]\n",
    "\n",
    "    corr = []\n",
    "    for i in range(velocity.shape[1]):\n",
    "        corr.append(\n",
    "            scipy.stats.pearsonr(np.array(velocity_gt.todense()[:, i]).ravel(), np.array(velocity[:, i]).ravel())\n",
    "        )\n",
    "\n",
    "    corr = np.array(corr)[:, 0]\n",
    "    unitvelo_corr = corr\n",
    "\n",
    "    ## calculate veloVAE\n",
    "    adata_vv = adata_utv.copy()\n",
    "    vae = vv.VAE(adata_vv, tmax=20, dim_z=10, device=\"cuda:0\")\n",
    "\n",
    "    config = {\n",
    "        # You can change any hyperparameters here!\n",
    "    }\n",
    "    vae.train(adata_vv, config=config, plot=False, embed=\"dimred\")\n",
    "\n",
    "    file_name = adata_name + \"_sim_vae.h5ad\"\n",
    "    vae.save_anndata(adata_vv, \"vae\", \"GRN_benchmark\", file_name=file_name)\n",
    "\n",
    "    ## calculate veloVAE(VAE)\n",
    "    velocity_gt = adata_vv.layers[\"rna_velocity\"]\n",
    "    velocity = adata_vv.layers[\"vae_velocity\"]\n",
    "\n",
    "    corr = []\n",
    "    for i in range(velocity.shape[1]):\n",
    "        corr.append(\n",
    "            scipy.stats.pearsonr(np.array(velocity_gt.todense()[:, i]).ravel(), np.array(velocity[:, i]).ravel())\n",
    "        )\n",
    "\n",
    "    vae_corr = np.array(corr)[:, 0]\n",
    "\n",
    "    try:\n",
    "        # Perform some computation in f(a)\n",
    "        rate_prior = {\"alpha\": (0, 1.0), \"beta\": (0, 0.5), \"gamma\": (0, 0.5)}\n",
    "        full_vb = vv.VAE(adata_vv, tmax=20, dim_z=10, device=\"cuda:0\", full_vb=True, rate_prior=rate_prior)\n",
    "\n",
    "        config = {\n",
    "            # You can change any hyperparameters here!\n",
    "        }\n",
    "        full_vb.train(adata_vv, config=config, plot=False, embed=\"dimred\")\n",
    "\n",
    "        file_name = adata_name + \"_sim_fullvb.h5ad\"\n",
    "        full_vb.save_anndata(adata_vv, \"fullvb\", \"GRN_benchmark\", file_name=file_name)\n",
    "\n",
    "        velocity_gt = adata_vv.layers[\"rna_velocity\"]\n",
    "        velocity = adata_vv.layers[\"fullvb_velocity\"]\n",
    "\n",
    "        corr = []\n",
    "        for i in range(velocity.shape[1]):\n",
    "            corr.append(\n",
    "                scipy.stats.pearsonr(np.array(velocity_gt.todense()[:, i]).ravel(), np.array(velocity[:, i]).ravel())\n",
    "            )\n",
    "\n",
    "        fullvb_corr = np.array(corr)[:, 0]\n",
    "        # If no error is raised, break the loop and return the result\n",
    "    except:\n",
    "        # If an error is raised, increment a and try again, and need to recompute double knock-out reults\n",
    "        fullvb_corr = [np.nan] * len(vae_corr)\n",
    "        raise\n",
    "\n",
    "    # Done velocity!\n",
    "    # calculate correlation\n",
    "    regulator_index = [i in adata.uns[\"regulators\"] for i in adata.var.index.values]\n",
    "    target_index = [i in adata.uns[\"targets\"] for i in adata.var.index.values]\n",
    "\n",
    "    corr_m = 1 - cdist(adata.layers[\"Ms\"].T, adata.layers[\"Ms\"].T, metric=\"correlation\")\n",
    "    corr_m = torch.tensor(corr_m)\n",
    "    corr_m = corr_m[target_index,]\n",
    "    corr_m = corr_m[:, regulator_index]\n",
    "    corr_m = corr_m.float()\n",
    "\n",
    "    GRN = torch.mean(Jaco_m, 2)\n",
    "\n",
    "    GRN_weight = reg_vae.module.v_encoder.fc1.weight.detach()\n",
    "\n",
    "    ### Run GRNBoost2 to benchmark the GRN inference performance\n",
    "    GEP = pd.DataFrame(adata.layers[\"Ms\"], columns=adata.var.index.values)\n",
    "    local_cluster = LocalCluster()\n",
    "    client = Client(local_cluster)\n",
    "    network = grnboost2(expression_data=GEP, tf_names=adata.uns[\"regulators\"], client_or_address=client)\n",
    "\n",
    "    client.close()\n",
    "    local_cluster.close()\n",
    "\n",
    "    ind = [i in adata.uns[\"targets\"] for i in network[\"target\"]]\n",
    "    network = network[ind]\n",
    "\n",
    "    grnboost_m = np.zeros((len(adata.uns[\"targets\"]), len(adata.uns[\"regulators\"])))\n",
    "    grnboost_m = pd.DataFrame(grnboost_m, index=adata.uns[\"targets\"], columns=adata.uns[\"regulators\"])\n",
    "    for i in adata.uns[\"targets\"]:\n",
    "        for j in adata.uns[\"regulators\"]:\n",
    "            ind = (network[\"TF\"] == j) & (network[\"target\"] == i)\n",
    "            if sum(ind) > 0:\n",
    "                pdd = network[ind]\n",
    "                grnboost_m.loc[i, j] = pdd[\"importance\"].values\n",
    "\n",
    "    Jaco_m = Jaco_m.cpu().detach()\n",
    "    GRN = GRN.cpu().detach()\n",
    "    GRN_weight = GRN_weight.cpu().detach()\n",
    "\n",
    "    score = csgn_benchmark2(torch.abs(Jaco_m), GRN_gt, adata.uns[\"csgn\"])\n",
    "    score2 = csgn_benchmark2(torch.abs(GRN), GRN_gt, adata.uns[\"csgn\"])\n",
    "    score3 = csgn_benchmark2(torch.abs(GRN_weight), GRN_gt, adata.uns[\"csgn\"])\n",
    "    score4 = csgn_benchmark2(torch.abs(corr_m), GRN_gt, adata.uns[\"csgn\"])\n",
    "    score5 = csgn_benchmark2(torch.tensor(np.array(grnboost_m)), GRN_gt, adata.uns[\"csgn\"])\n",
    "\n",
    "    score_all = csgn_benchmark2(torch.abs(Jaco_m), W, adata.uns[\"csgn\"])\n",
    "    score2_all = csgn_benchmark2(torch.abs(GRN), W, adata.uns[\"csgn\"])\n",
    "    score3_all = csgn_benchmark2(torch.abs(GRN_weight), W, adata.uns[\"csgn\"])\n",
    "    score4_all = csgn_benchmark2(torch.abs(corr_m), W, adata.uns[\"csgn\"])\n",
    "    score5_all = csgn_benchmark2(torch.tensor(np.array(grnboost_m)), W, adata.uns[\"csgn\"])\n",
    "\n",
    "    ### Visualize the Violin Plots\n",
    "    AUROC = [np.mean(score), np.mean(score2), np.mean(score3), np.mean(score4), np.mean(score5)]\n",
    "    AUROC_all = [np.mean(score_all), np.mean(score2_all), np.mean(score3_all), np.mean(score4_all), np.mean(score5_all)]\n",
    "    AUC_GRN_result.append(AUROC)\n",
    "    AUC_GRN_result_all.append(AUROC_all)\n",
    "    print(AUROC)\n",
    "    print(AUROC_all)\n",
    "\n",
    "    fit_t_dynamical = adata.layers[\"fit_t_dynamical\"]\n",
    "    fit_t_velovi = adata.layers[\"fit_t_velovi\"]\n",
    "    fit_t_regvelo = adata_target.layers[\"fit_t\"]\n",
    "\n",
    "    ## gene specific latent time correlation with ground truth\n",
    "    velocity = adata_target.layers[\"velocity\"]\n",
    "    corr = []\n",
    "    for i in range(velocity.shape[1]):\n",
    "        corr.append(scipy.stats.spearmanr(fit_t_dynamical[:, i], adata_target.obs[\"sim_time\"]))\n",
    "\n",
    "    corr = np.array(corr)[:, 0]\n",
    "    corr_latent_time_dynamical = corr\n",
    "\n",
    "    velocity = adata_target.layers[\"velocity\"]\n",
    "    corr = []\n",
    "    for i in range(velocity.shape[1]):\n",
    "        corr.append(scipy.stats.spearmanr(fit_t_velovi[:, i], adata_target.obs[\"sim_time\"]))\n",
    "\n",
    "    corr = np.array(corr)[:, 0]\n",
    "    corr_latent_time_velovi = corr\n",
    "\n",
    "    velocity = adata_target.layers[\"velocity\"]\n",
    "    corr = []\n",
    "    for i in range(velocity.shape[1]):\n",
    "        corr.append(scipy.stats.spearmanr(fit_t_regvelo[:, i], adata_target.obs[\"sim_time\"]))\n",
    "\n",
    "    corr = np.array(corr)[:, 0]\n",
    "    corr_latent_time_regvelo = corr\n",
    "\n",
    "    ## outputs\n",
    "\n",
    "    gene_time_corr_res = [\n",
    "        np.mean(corr_latent_time_dynamical),\n",
    "        np.mean(corr_latent_time_velovi),\n",
    "        np.mean(corr_latent_time_regvelo),\n",
    "    ]\n",
    "\n",
    "    ## calculate velocity correlation\n",
    "    gene_velo_corr_res = [\n",
    "        np.mean(dynamical_corr),\n",
    "        np.mean(deterministic_corr),\n",
    "        np.mean(stochastic_corr),\n",
    "        np.mean(velovi_corr),\n",
    "        np.mean(regvelo_corr),\n",
    "        np.mean(unitvelo_corr),\n",
    "        np.mean(fullvb_corr),\n",
    "        np.mean(vae_corr),\n",
    "    ]\n",
    "\n",
    "    gene_time_corr_all.append(gene_time_corr_res)\n",
    "    gene_velo_corr_all.append(gene_velo_corr_res)\n",
    "\n",
    "    df = pd.DataFrame(gene_velo_corr_all)\n",
    "    df.columns = [\n",
    "        \"dynamical\",\n",
    "        \"deterministic\",\n",
    "        \"stochastic\",\n",
    "        \"velovi\",\n",
    "        \"regvelo\",\n",
    "        \"UniTVelo\",\n",
    "        \"VeloVAE(fullvb)\",\n",
    "        \"VeloVAE(vae)\",\n",
    "    ]\n",
    "\n",
    "    if SAVE_DATASETS:\n",
    "        df.to_csv(DATA_DIR / \"simulation\" / \"dyngen_results\" / \"gene_velo_corr_all_final_res.csv\")\n",
    "\n",
    "    df = pd.DataFrame(gene_time_corr_all)\n",
    "    df.columns = [\"dynamical\", \"velovi\", \"regvelo\"]\n",
    "\n",
    "    if SAVE_DATASETS:\n",
    "        df.to_csv(DATA_DIR / \"simulation\" / \"dyngen_results\" / \"gene_time_corr_all_final_res.csv\")\n",
    "\n",
    "    df = pd.DataFrame(AUC_GRN_result)\n",
    "    df.columns = [\"Jaco\", \"GRN_mean\", \"GRN_weight\", \"corr_m\", \"GRNBoost2\"]\n",
    "\n",
    "    if SAVE_DATASETS:\n",
    "        df.to_csv(DATA_DIR / \"simulation\" / \"dyngen_results\" / \"AUROC_res_all_final_res.csv\")\n",
    "\n",
    "    df = pd.DataFrame(AUC_GRN_result_all)\n",
    "    df.columns = [\"Jaco\", \"GRN_mean\", \"GRN_weight\", \"corr_m\", \"GRNBoost2\"]\n",
    "\n",
    "    if SAVE_DATASETS:\n",
    "        df.to_csv(DATA_DIR / \"simulation\" / \"dyngen_results\" / \"AUROC_res_all_full_final_res.csv\")\n",
    "\n",
    "    print(\"Done \" + adata_name + \"!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe90bba-2cda-4b57-b7a4-0a97802cb2af",
   "metadata": {},
   "source": [
    "## Benchmark analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273cad0-6ec0-4ad8-b745-c5f15642c903",
   "metadata": {},
   "source": [
    "### Velocity benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2afab8f-092d-47e3-b989-351971a46f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFvelo = pd.read_csv(\"RegVelo_datasets/dyngen_benchmark/TFvelo_res.csv\", index_col=0)\n",
    "cell2fate = pd.read_csv(\"RegVelo_datasets/dyngen_benchmark/c2f_velo_cor.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "872dd501-ab0a-40fb-b3b4-b6d4c4dc622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_gene_velo = pd.read_csv(\n",
    "    DATA_DIR / \"simulation\" / \"dyngen_results\" / \"gene_velo_corr_all_final_res.csv\", index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b53daf5-96d9-4510-8f6e-09b0c95d8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_gene_velo.columns = [\n",
    "    \"scVelo\",\n",
    "    \"scVelo(deterministic)\",\n",
    "    \"scVelo(stochastic)\",\n",
    "    \"veloVI\",\n",
    "    \"RegVelo\",\n",
    "    \"UniTVelo\",\n",
    "    \"VeloVAE(vae)\",\n",
    "    \"VeloVAE(fullvb)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9c6556f-35b3-4f66-b3a5-658cfd2dd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = full_gene_velo.T\n",
    "result_df.loc[:, \"index\"] = result_df.index\n",
    "new_df = pd.melt(result_df, id_vars=[\"index\"], value_name=\"Performance\", var_name=\"Method\")\n",
    "new_df = new_df.iloc[:, [0, 2]].copy()\n",
    "new_df.columns = [\"Method\", \"Performance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e14d13c3-59f9-449a-baf3-f34823ecddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.append(pd.DataFrame({\"Method\": \"TFvelo\", \"Performance\": TFvelo[\"velocity_corr\"]}))\n",
    "new_df = new_df.append(pd.DataFrame({\"Method\": \"cell2fate\", \"Performance\": cell2fate.iloc[:, 0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "821c35ae-12d2-4682-9597-889b4478e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"Method\"] = pd.Categorical(\n",
    "    new_df[\"Method\"],\n",
    "    categories=[\n",
    "        \"RegVelo\",\n",
    "        \"veloVI\",\n",
    "        \"scVelo\",\n",
    "        \"scVelo(stochastic)\",\n",
    "        \"scVelo(deterministic)\",\n",
    "        \"UniTVelo\",\n",
    "        \"VeloVAE(vae)\",\n",
    "        \"VeloVAE(fullvb)\",\n",
    "        \"TFvelo\",\n",
    "        \"cell2fate\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4def7825-92cf-4bec-9047-5fa3baefe09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.loc[:, \"Performance\"] = (new_df.loc[:, \"Performance\"] + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0de9d-2d6b-4bf2-95c2-d5781a61133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mplscience.style_context():\n",
    "    sns.set_style(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "\n",
    "    # sns.violinplot(data=new_df, x=\"Method\", y=\"Performance\", palette=\"colorblind\", ax=ax)\n",
    "    colors = sns.color_palette(\"colorblind\", n_colors=3)\n",
    "    colors = colors + [\"lightgrey\"] * 7\n",
    "    sns.violinplot(data=new_df, y=\"Method\", x=\"Performance\", ax=ax, palette=colors, linewidth=0.8)\n",
    "\n",
    "    ttest_res = wilcoxon(\n",
    "        new_df.iloc[:, 1][new_df.iloc[:, 0] == \"RegVelo\"].values,\n",
    "        new_df.iloc[:, 1][new_df.iloc[:, 0] == \"veloVI\"].values,\n",
    "        alternative=\"greater\",\n",
    "    )\n",
    "    significance = get_significance(ttest_res.pvalue)\n",
    "    add_significance2(\n",
    "        ax=ax,\n",
    "        bottom=0,\n",
    "        top=1,\n",
    "        significance=significance,\n",
    "        lw=1,\n",
    "        bracket_level=1.05,\n",
    "        c=\"k\",\n",
    "        level=0,\n",
    "    )\n",
    "\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    ax.set(ylabel=\"\", xlabel=\"Velocity correlation\")\n",
    "    ax.set_xlim([x_min, x_max + 0.02])\n",
    "\n",
    "    if SAVE_FIGURES:\n",
    "        fig.savefig(\n",
    "            FIG_DIR / \"simulation\" / \"dyngen_results\" / \"velocity_benchmark.svg\",\n",
    "            format=\"svg\",\n",
    "            transparent=True,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd3230-050c-4027-8a24-281f475672c5",
   "metadata": {},
   "source": [
    "### Latent time benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04d87b8c-9ed6-47e2-b23a-27a3c5fac706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_DIR / \"simulation\" / \"dyngen_results\" / \"gene_time_corr_all_final_res.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b326b560-5858-4eac-a6cd-13545376c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.T\n",
    "result.index = [\"scVelo\", \"veloVI\", \"RegVelo\"]\n",
    "result.loc[:, \"index\"] = result.index\n",
    "new_df = pd.melt(result, id_vars=[\"index\"], value_name=\"Performance\", var_name=\"Method\")\n",
    "new_df = new_df.iloc[:, [0, 2]].copy()\n",
    "new_df.columns = [\"Method\", \"Performance\"]\n",
    "new_df[\"Method\"] = pd.Categorical(new_df[\"Method\"], categories=[\"RegVelo\", \"veloVI\", \"scVelo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c158bc-d90c-4824-af3d-428feaa01951",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mplscience.style_context():\n",
    "    sns.set_style(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(3, 2))\n",
    "    # pal = {\"RegVelo\":\"#f3e1eb\",\"veloVI\":\"#b5bbe3\",\"scVelo\":\"#0fcfc0\"}\n",
    "    sns.violinplot(data=new_df, y=\"Method\", x=\"Performance\", ax=ax)\n",
    "\n",
    "    ttest_res = wilcoxon(\n",
    "        new_df.iloc[:, 1][new_df.iloc[:, 0] == \"RegVelo\"].values,\n",
    "        new_df.iloc[:, 1][new_df.iloc[:, 0] == \"veloVI\"].values,\n",
    "        alternative=\"greater\",\n",
    "    )\n",
    "    significance = get_significance(ttest_res.pvalue)\n",
    "    add_significance2(\n",
    "        ax=ax,\n",
    "        bottom=0,\n",
    "        top=1,\n",
    "        significance=significance,\n",
    "        lw=1,\n",
    "        bracket_level=1.05,\n",
    "        c=\"k\",\n",
    "        level=0,\n",
    "    )\n",
    "\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set(ylabel=\"\", xlabel=\"latent time correlation\")\n",
    "    ax.set_ylim([y_min, y_max + 0.02])\n",
    "    if SAVE_FIGURES:\n",
    "        fig.savefig(\n",
    "            FIG_DIR / \"simulation\" / \"dyngen_results\" / \"latent_time_benchmark.svg\",\n",
    "            format=\"svg\",\n",
    "            transparent=True,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde298fa-6b58-429a-adc1-2d173c104a70",
   "metadata": {},
   "source": [
    "### GRN inference benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5233a6f0-c4de-411a-ac68-66793b1e945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co = pd.read_csv(\"RegVelo_datasets/dyngen_benchmark/AUROC_res_all_celloracle.csv\", index_col=0)\n",
    "df_spliceJAC = pd.read_csv(\"RegVelo_datasets/dyngen_benchmark/AUROC_res_all_spliceAJ.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18cf9b3b-bf4f-4b63-ae5c-e46fae219162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_DIR / \"simulation\" / \"dyngen_results\" / \"AUROC_res_all_full_final_res.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d2463fb-76ac-4031-8256-b83a867948d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = (\n",
    "    df.iloc[:, 0].tolist()\n",
    "    + df.iloc[:, 3].tolist()\n",
    "    + df.iloc[:, 4].tolist()\n",
    "    + df_co.iloc[:, 0].tolist()\n",
    "    + df_spliceJAC.iloc[:, 0].tolist()\n",
    "    + TFvelo.iloc[:, 0].tolist()\n",
    ")\n",
    "method = (\n",
    "    [\"RegVelo\"] * len(df.iloc[:, 0].tolist())\n",
    "    + [\"Cor\"] * len(df.iloc[:, 0].tolist())\n",
    "    + [\"GRNBoost2\"] * len(df.iloc[:, 0].tolist())\n",
    "    + [\"CellOracle\"] * len(df_co.iloc[:, 0].tolist())\n",
    "    + [\"spliceJAC\"] * len(df_spliceJAC.iloc[:, 0].tolist())\n",
    "    + [\"TFvelo\"] * TFvelo.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb67e625-2aa6-4dad-9d65-db4c0f7b2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({\"Method\": method, \"Performance\": performance})\n",
    "new_df = new_df.loc[~np.isnan(new_df.iloc[:, 1]), :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd151a8f-c3b1-4714-abd5-44ef67fed379",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mplscience.style_context():\n",
    "    sns.set_style(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "\n",
    "    # sns.violinplot(data=result, x=\"Method\", y=\"Performance\", palette=\"colorblind\",order = [\"RegVelo\",\"GRNBoost2\",\"CellOracle\",\"Cor\",\"spliceJAC\"], ax=ax)\n",
    "    sns.violinplot(\n",
    "        data=new_df,\n",
    "        y=\"Method\",\n",
    "        x=\"Performance\",\n",
    "        color=\"lightpink\",\n",
    "        order=[\"RegVelo\", \"GRNBoost2\", \"CellOracle\", \"Cor\", \"spliceJAC\", \"TFvelo\"],\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ttest_res = wilcoxon(\n",
    "        new_df.iloc[:, 1][new_df.iloc[:, 0] == \"RegVelo\"].values,\n",
    "        new_df.iloc[:, 1][new_df.iloc[:, 0] == \"GRNBoost2\"].values,\n",
    "        alternative=\"greater\",\n",
    "    )\n",
    "    significance = get_significance(ttest_res.pvalue)\n",
    "    add_significance2(\n",
    "        ax=ax,\n",
    "        bottom=0,\n",
    "        top=1,\n",
    "        significance=significance,\n",
    "        lw=1,\n",
    "        bracket_level=1.05,\n",
    "        c=\"k\",\n",
    "        level=0,\n",
    "    )\n",
    "\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    ax.set(ylabel=\"\", xlabel=\"AUROC\")\n",
    "    ax.set_xlim([x_min, x_max + 0.02])\n",
    "    if SAVE_FIGURES:\n",
    "        fig.savefig(\n",
    "            FIG_DIR / \"simulation\" / \"dyngen_results\" / \"GRN_benchmark.svg\",\n",
    "            format=\"svg\",\n",
    "            transparent=True,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
