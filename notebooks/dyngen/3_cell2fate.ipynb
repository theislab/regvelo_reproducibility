{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87443fd1",
   "metadata": {},
   "source": [
    "# cell2fate benchmark on dyngen data\n",
    "\n",
    "Notebook benchmarks velocity and latent time inference using cell2fate on dyngen-generated data.\n",
    "\n",
    "Note that cell2fate requires `anndata==0.8.0` and `scvi-tools==0.16.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67153cd",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2abba759-163c-42c8-b826-7b91623a9fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 21:45:09.738523: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-28 21:46:06.193779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-28 21:46:06.207855: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-28 21:46:06.207871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc01f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Callable, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "import anndata as ad\n",
    "import cell2fate as c2f\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0a084b-12da-40a2-84cf-4901995d98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/lustre/groups/ml01/workspace/yifan.chen/regvelo_reproducibility/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b37db-3a15-4364-8eeb-1916ae7e4614",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4aa1b0-c83d-4de3-ab01-4c8c30ca3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for train model and get output\n",
    "def train_c2f_model(adata):\n",
    "    \"\"\"cell2fate pipeline.\"\"\"\n",
    "    c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label=\"spliced_raw\", unspliced_label=\"unspliced_raw\")\n",
    "    n_modules = c2f.utils.get_max_modules(adata)\n",
    "    mod = c2f.Cell2fate_DynamicalModel(adata, n_modules=n_modules)\n",
    "    mod.train()\n",
    "\n",
    "    adata = mod.export_posterior(\n",
    "        adata, sample_kwargs={\"batch_size\": None, \"num_samples\": 30, \"return_samples\": True, \"use_gpu\": False}\n",
    "    )\n",
    "    adata = mod.compute_module_summary_statistics(adata)\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        adata.layers[\"Spliced Mean\"] = mod.samples[\"post_sample_means\"][\"mu_expression\"][..., 1]\n",
    "        c2f_velocity = (\n",
    "            torch.tensor(mod.samples[\"post_sample_means\"][\"beta_g\"])\n",
    "            * mod.samples[\"post_sample_means\"][\"mu_expression\"][..., 0]\n",
    "            - torch.tensor(mod.samples[\"post_sample_means\"][\"gamma_g\"])\n",
    "            * mod.samples[\"post_sample_means\"][\"mu_expression\"][..., 1]\n",
    "        )\n",
    "        adata.layers[\"velocity\"] = c2f_velocity.numpy()\n",
    "\n",
    "    adata.layers[\"Ms\"] = adata.layers[\"spliced\"].copy()\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8119b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsonr(x: ArrayLike, y: ArrayLike, axis: int = 0) -> ArrayLike:\n",
    "    \"\"\"Compute Pearson correlation between axes of two arrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x\n",
    "        Input array.\n",
    "    y\n",
    "        Input array.\n",
    "    axis\n",
    "        Axis along which Pearson correlation is computed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Axis-wise Pearson correlations.\n",
    "    \"\"\"\n",
    "    centered_x = x - np.mean(x, axis=axis, keepdims=True)\n",
    "    centered_y = y - np.mean(y, axis=axis, keepdims=True)\n",
    "\n",
    "    r_num = np.add.reduce(centered_x * centered_y, axis=axis)\n",
    "    r_den = np.sqrt((centered_x * centered_x).sum(axis=axis) * (centered_y * centered_y).sum(axis=axis))\n",
    "\n",
    "    return r_num / r_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f1c80c6-52cd-440d-b788-fcd3d503d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_velocity_correlation(\n",
    "    ground_truth: ArrayLike, estimated: ArrayLike, aggregation: Union[Callable, None], axis: int = 0\n",
    ") -> Union[ArrayLike, float]:\n",
    "    \"\"\"Compute Pearson correlation between ground truth and estimated values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ground_truth\n",
    "        Array of ground truth value.\n",
    "    estimated\n",
    "        Array of estimated values.\n",
    "    aggregation\n",
    "        If `None`, the function returns every pairwise correlation between ground truth and the estimate. If it is a\n",
    "        function, the correlations are aggregated accordningly.\n",
    "    axis\n",
    "        Axis along which ground truth and estimate is compared.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Axis-wise Pearson correlations potentially aggregated.\n",
    "    \"\"\"\n",
    "    correlation = pearsonr(ground_truth, estimated, axis=axis)\n",
    "\n",
    "    if aggregation is None:\n",
    "        return correlation\n",
    "    elif callable(aggregation):\n",
    "        return aggregation(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf5e643-a580-4b81-b298-1aec0291064e",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d018064-5b61-46fe-b196-d390998e6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"dyngen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8309529-c3f1-456a-aabc-d11e88a4f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLEXITY = \"complexity_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "054d67d8-c98f-4e60-bb4a-ce3ecdbbf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DATA = True\n",
    "if SAVE_DATA:\n",
    "    (DATA_DIR / DATASET / COMPLEXITY / \"results\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a79d3cd-6bd7-4d5e-8a95-95d0a559bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DATASETS = True\n",
    "if SAVE_DATASETS:\n",
    "    (DATA_DIR / DATASET / COMPLEXITY / \"trained_cell2fate\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d521216d-bef9-42f7-bd17-5c006c4c8c1e",
   "metadata": {},
   "source": [
    "## Velocity pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_correlation = []\n",
    "\n",
    "cnt = 0\n",
    "for filename in (DATA_DIR / DATASET / COMPLEXITY / \"processed\").iterdir():\n",
    "    torch.cuda.empty_cache()\n",
    "    if filename.suffix != \".zarr\":\n",
    "        continue\n",
    "\n",
    "    simulation_id = int(filename.stem.removeprefix(\"simulation_\"))\n",
    "    print(f\"Run {cnt}, dataset {simulation_id}.\")\n",
    "\n",
    "    adata = ad.read_zarr(filename)\n",
    "\n",
    "    ## cell2fate needs cluster information\n",
    "    sc.tl.leiden(adata)\n",
    "\n",
    "    adata = c2f.utils.get_training_data(\n",
    "        adata,\n",
    "        cells_per_cluster=10**5,\n",
    "        cluster_column=\"leiden\",\n",
    "        remove_clusters=[],\n",
    "    )\n",
    "\n",
    "    adata = train_c2f_model(adata)\n",
    "\n",
    "    # save data\n",
    "    adata.write_zarr(DATA_DIR / DATASET / COMPLEXITY / \"trained_cell2fate\" / f\"trained_{simulation_id}.zarr\")\n",
    "\n",
    "    velocity_correlation.append(\n",
    "        get_velocity_correlation(\n",
    "            ground_truth=adata.layers[\"true_velocity\"], estimated=adata.layers[\"velocity\"], aggregation=np.mean\n",
    "        )\n",
    "    )\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dfb57fd-4b7b-4449-8428-e42673b381c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_DATA:\n",
    "    pd.DataFrame({\"velocity\": velocity_correlation}).to_parquet(\n",
    "        path=DATA_DIR / DATASET / COMPLEXITY / \"results\" / \"cell2fate_correlation.parquet\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (cell2fate_env)",
   "language": "python",
   "name": "cell2fate_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
