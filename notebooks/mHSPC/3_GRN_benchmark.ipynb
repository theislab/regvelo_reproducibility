{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c224a598-ec68-4f33-bea0-923806c4ca7a",
   "metadata": {},
   "source": [
    "# Run other GRN inference methods on mHSPC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cecbff5-757e-42b6-8fe7-cb9a9b1cf0e9",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d444ee-12ef-4b05-a693-f0cc02caa241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import celloracle as co\n",
    "import scanpy as sc\n",
    "from arboreto.algo import grnboost2\n",
    "\n",
    "from rgv_tools import DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeae04a-6f43-4902-a5b4-2f131013c2d1",
   "metadata": {},
   "source": [
    "## General setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2251dc-36ad-4902-aeff-a0cd91c295a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1a7bc-6e0d-4818-b81b-4270b5085a9b",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b2a2ad-4c83-4bee-9fc6-2d68dbdce7cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET = \"mHSPC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada6221f-9045-4275-a8d2-42ba4bf5622d",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVE_DATA = True\n",
    "if SAVE_DATA:\n",
    "    (DATA_DIR / DATASET / \"results\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951248fb-f505-4c55-b2cb-5c7430be5e1d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Functions definations\n",
    "We followed the GRN benchmark workflow provided by BEELINE, please check https://github.com/Murali-group/Beeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7926ea6d-859a-493d-86cc-b1cf9a955f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unsigned(true_edges: pd.DataFrame, pred_edges: pd.DataFrame, type: str = \"alledges\") -> tuple[float, float, float]:\n",
    "    \"\"\"Compare true vs predicted edges (unsigned) and compute precision/recall metrics.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        tuple: (eprec, erec, eprec_ratio)\n",
    "    \"\"\"\n",
    "    true_edges_copy = true_edges.copy()\n",
    "    pred_edges_copy = pred_edges.copy()\n",
    "\n",
    "    # Drop self-edges and duplicates\n",
    "    true_edges_copy = true_edges_copy.loc[(true_edges_copy[\"Gene1\"] != true_edges_copy[\"Gene2\"])]\n",
    "    true_edges_copy.drop_duplicates(keep=\"first\", inplace=True)\n",
    "    true_edges_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    pred_edges_copy = pred_edges_copy.loc[(pred_edges_copy[\"Gene1\"] != pred_edges_copy[\"Gene2\"])]\n",
    "    pred_edges_copy.drop_duplicates(keep=\"first\", inplace=True)\n",
    "    pred_edges_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Get a list of all possible TF to gene interactions\n",
    "    unique_nodes = np.unique(true_edges_copy.loc[:, [\"Gene1\", \"Gene2\"]])\n",
    "    possible_edges_all = set(product(set(true_edges_copy.Gene1), set(unique_nodes)))\n",
    "\n",
    "    # Get a list of all possible interactions\n",
    "    possible_edges_no_self = set(permutations(unique_nodes, r=2))\n",
    "\n",
    "    # Find intersection of above lists to ignore self edges\n",
    "    possible_edges = possible_edges_all.intersection(possible_edges_no_self)\n",
    "\n",
    "    true_edges_dict = {\"|\".join(p): 0 for p in possible_edges}\n",
    "\n",
    "    true_edges_str = true_edges_copy[\"Gene1\"] + \"|\" + true_edges_copy[\"Gene2\"]\n",
    "    true_edges_str = true_edges_str[true_edges_str.isin(true_edges_dict)]\n",
    "    n_edges = len(true_edges_str)\n",
    "\n",
    "    pred_edges_copy[\"Edges\"] = pred_edges_copy[\"Gene1\"] + \"|\" + pred_edges_copy[\"Gene2\"]\n",
    "    pred_edges_copy = pred_edges_copy[pred_edges_copy[\"Edges\"].isin(true_edges_dict)]\n",
    "    pred_edges_copy.copy()\n",
    "\n",
    "    if not pred_edges_copy.shape[0] == 0:\n",
    "        pred_edges_copy.loc[:, \"EdgeWeight\"] = pred_edges_copy.EdgeWeight.round(6).abs()\n",
    "        pred_edges_copy.sort_values(by=\"EdgeWeight\", ascending=False, inplace=True)\n",
    "\n",
    "        maxk = min(pred_edges_copy.shape[0], n_edges)\n",
    "        edge_weight_topk = pred_edges_copy.iloc[maxk - 1].EdgeWeight\n",
    "\n",
    "        nnz_min = np.nanmin(pred_edges_copy.EdgeWeight.replace(0, np.nan).values)\n",
    "        best_val = max(nnz_min, edge_weight_topk)\n",
    "\n",
    "        newDF = pred_edges_copy.loc[(pred_edges_copy[\"EdgeWeight\"] >= best_val)]\n",
    "        rank = set(newDF[\"Gene1\"] + \"|\" + newDF[\"Gene2\"])\n",
    "\n",
    "        intersectionSet = rank.intersection(true_edges_str)\n",
    "        eprec = len(intersectionSet) / len(rank)\n",
    "        erec = len(intersectionSet) / len(true_edges_str)\n",
    "\n",
    "        random_eprec = n_edges / len(true_edges_dict)\n",
    "        eprec_ratio = eprec / random_eprec\n",
    "    else:\n",
    "        eprec = 1.0\n",
    "        erec = 1.0\n",
    "        eprec_ratio = 1.0\n",
    "\n",
    "    print(\"EPR: \" + str(eprec_ratio))\n",
    "    return eprec, erec, eprec_ratio\n",
    "\n",
    "\n",
    "def calculate_auroc(inferred_scores_df: pd.DataFrame, ground_truth_df: pd.DataFrame) -> float:\n",
    "    \"\"\"Calculate AUROC comparing inferred edge scores against ground truth.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        float: AUROC score.\n",
    "    \"\"\"\n",
    "    ground_truth_set = set(zip(ground_truth_df[\"Gene1\"], ground_truth_df[\"Gene2\"]))\n",
    "\n",
    "    inferred_scores_df[\"label\"] = inferred_scores_df.apply(\n",
    "        lambda row: (row[\"Gene1\"], row[\"Gene2\"]) in ground_truth_set, axis=1\n",
    "    ).astype(int)\n",
    "\n",
    "    y_true = inferred_scores_df[\"label\"]\n",
    "    y_scores = inferred_scores_df[\"EdgeWeight\"]\n",
    "\n",
    "    auroc = roc_auc_score(y_true, y_scores)\n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea1a8d-c09e-419b-9081-206acb081c13",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae45641b-d451-450f-a027-8692d94b87c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(DATA_DIR / DATASET / \"processed\" / \"mHSC_ExpressionData.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e132516-ed34-4781-8ddd-abdda2825067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gt = pd.read_csv(DATA_DIR / DATASET / \"raw\" / \"mHSC-ChIP-seq-network.csv\")\n",
    "TF = pd.read_csv(DATA_DIR / DATASET / \"raw\" / \"mouse-tfs.csv\")\n",
    "TF = [i[0].upper() + i[1:].lower() for i in TF[\"TF\"].tolist()]\n",
    "TF = np.array(TF)[[i in adata.var_names for i in TF]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507f1b13-47ac-49ff-b7af-977410dd7fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene1</th>\n",
       "      <th>Gene2</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24829</th>\n",
       "      <td>Bcl11b</td>\n",
       "      <td>Ccna2</td>\n",
       "      <td>2546.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24913</th>\n",
       "      <td>Bcl11b</td>\n",
       "      <td>Edem1</td>\n",
       "      <td>2532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24928</th>\n",
       "      <td>Bcl11b</td>\n",
       "      <td>Tmem229b</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25015</th>\n",
       "      <td>Bcl11b</td>\n",
       "      <td>Clptm1l</td>\n",
       "      <td>1598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25037</th>\n",
       "      <td>Bcl11b</td>\n",
       "      <td>Cyld</td>\n",
       "      <td>2156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942678</th>\n",
       "      <td>Stat3</td>\n",
       "      <td>Abcg3</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942681</th>\n",
       "      <td>Stat3</td>\n",
       "      <td>Il10</td>\n",
       "      <td>607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942686</th>\n",
       "      <td>Stat3</td>\n",
       "      <td>Arg1</td>\n",
       "      <td>499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942696</th>\n",
       "      <td>Stat3</td>\n",
       "      <td>Mmp9</td>\n",
       "      <td>445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942698</th>\n",
       "      <td>Stat3</td>\n",
       "      <td>Cd209a</td>\n",
       "      <td>437.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8940 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gene1     Gene2   Score\n",
       "24829   Bcl11b     Ccna2  2546.0\n",
       "24913   Bcl11b     Edem1  2532.0\n",
       "24928   Bcl11b  Tmem229b  2023.0\n",
       "25015   Bcl11b   Clptm1l  1598.0\n",
       "25037   Bcl11b      Cyld  2156.0\n",
       "...        ...       ...     ...\n",
       "942678   Stat3     Abcg3   101.0\n",
       "942681   Stat3      Il10   607.0\n",
       "942686   Stat3      Arg1   499.0\n",
       "942696   Stat3      Mmp9   445.0\n",
       "942698   Stat3    Cd209a   437.0\n",
       "\n",
       "[8940 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt[\"Gene1\"] = [i[0].upper() + i[1:].lower() for i in gt[\"Gene1\"].tolist()]\n",
    "gt[\"Gene2\"] = [i[0].upper() + i[1:].lower() for i in gt[\"Gene2\"].tolist()]\n",
    "gt = gt.loc[[i in TF for i in gt[\"Gene1\"]], :]\n",
    "gt = gt.loc[[i in adata.var_names for i in gt[\"Gene2\"]], :]\n",
    "gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b138c350-8a08-49d1-a14d-2eb59bb7e0e2",
   "metadata": {},
   "source": [
    "## Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d63878f8-6cc4-4df4-bc39-b4008db3caad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grn_estimate = adata.to_df(layer=\"Ms\").corr().values\n",
    "np.fill_diagonal(grn_estimate, 0)\n",
    "\n",
    "grn_estimate = np.abs(grn_estimate)\n",
    "grn_estimate = pd.DataFrame(grn_estimate, index=adata.var_names.tolist(), columns=adata.var_names.tolist())\n",
    "\n",
    "grn_estimate = grn_estimate.loc[:, TF].copy()\n",
    "\n",
    "grn = pd.DataFrame(grn_estimate.stack()).reset_index()\n",
    "grn.columns = [\"Gene2\", \"Gene1\", \"EdgeWeight\"]\n",
    "\n",
    "result = grn[[\"Gene1\", \"Gene2\", \"EdgeWeight\"]].sort_values(by=\"EdgeWeight\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f770114-fe65-4a8d-9707-734cca6854b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94170, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f244c8fc-bbaa-437c-83ac-b88b009f8a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPR: 1.1085224655249315\n"
     ]
    }
   ],
   "source": [
    "_, _, epr_cor = unsigned(gt, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd6581cc-fdb4-40b9-8429-37b06de5ac93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5660399003249793"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_cor = calculate_auroc(result, gt)\n",
    "auc_cor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97859674-eead-4c8c-95b3-e45c4cb11712",
   "metadata": {},
   "source": [
    "## GRNBoost2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9ce9b09-6aa4-45c1-b25d-f5eddf3a0fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network = grnboost2(expression_data=adata.to_df(layer=\"Ms\"), tf_names=TF.tolist())\n",
    "grn_estimate = pd.pivot(network, index=\"target\", columns=\"TF\").fillna(0).values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e06a711-6ddb-41bd-b978-55e3212cc423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network.columns = [\"Gene1\", \"Gene2\", \"EdgeWeight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51a6530d-e7e4-4f08-842a-796838d31ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPR: 1.0147529772351342\n"
     ]
    }
   ],
   "source": [
    "_, _, epr_gbt2 = unsigned(gt, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3515e4d-32c4-4335-8b24-76990df4da2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5339281564361597"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_gbt2 = calculate_auroc(network, gt)\n",
    "auc_gbt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f89e1d-12f5-427b-a539-efc4ab19190e",
   "metadata": {},
   "source": [
    "## Using CellOracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1269cbc-9086-4096-a569-ef1c3ba5f533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_grn = np.ones((len(TF), adata.n_vars))\n",
    "base_grn = pd.DataFrame(base_grn, index=TF, columns=adata.var_names)\n",
    "base_grn[\"peak_id\"] = [\"peak_\" + i for i in TF]\n",
    "base_grn[\"gene_short_name\"] = TF\n",
    "base_grn = base_grn[[\"peak_id\", \"gene_short_name\"] + adata.var_names.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "787e301a-19f3-4718-a5ee-e6d30d0a1c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = co.Net(gene_expression_matrix=adata.to_df(layer=\"Ms\"), TFinfo_matrix=base_grn, verbose=False)\n",
    "net.fit_All_genes(bagging_number=100, alpha=1, verbose=False)\n",
    "net.updateLinkList(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9aa9c4f-11c9-4c24-a4ee-18d23d35603b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network = net.linkList[[\"source\", \"target\", \"coef_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c388bbc-e4a2-423c-9f4c-8a7219ffec48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network.columns = [\"Gene1\", \"Gene2\", \"EdgeWeight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5059d2ae-647f-426e-b3df-3d28d6802949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network[\"EdgeWeight\"] = np.abs(network[\"EdgeWeight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2099265-fc43-4549-9e08-a2c1742741fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPR: 1.1963372909401349\n"
     ]
    }
   ],
   "source": [
    "_, _, epr_co = unsigned(gt, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ffe9685-fbf2-4336-b50f-fdf37a20e878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55718676439274"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_co = calculate_auroc(network, gt)\n",
    "auc_co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13c82e-02ee-4479-88fb-113ff533cdb4",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03abb7d0-5d1b-4cf3-8eb0-dceb9c973780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(\n",
    "    {\n",
    "        \"EPR\": [epr_cor, epr_gbt2, epr_co],\n",
    "        \"AUC\": [auc_cor, auc_gbt2, auc_co],\n",
    "        \"Method\": [\"Corr\", \"GRNBoost2\", \"CellOracle\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "if SAVE_DATA:\n",
    "    result_df.to_csv(DATA_DIR / DATASET / \"results\" / \"GRN_benchmark.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502f43c-268b-4e98-9c45-5615ece4e173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:regvelo_test]",
   "language": "python",
   "name": "conda-env-regvelo_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
