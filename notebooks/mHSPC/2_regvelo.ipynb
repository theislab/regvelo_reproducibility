{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c224a598-ec68-4f33-bea0-923806c4ca7a",
   "metadata": {},
   "source": [
    "# Run RegVelo on mHSPC datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a19359-0801-4290-8907-74ad436f9f48",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d444ee-12ef-4b05-a693-f0cc02caa241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing CSCDataset from `anndata.experimental` is deprecated. Import anndata.abc.CSCDataset instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing CSRDataset from `anndata.experimental` is deprecated. Import anndata.abc.CSRDataset instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_elem from `anndata.experimental` is deprecated. Import anndata.io.read_elem instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scanpy as sc\n",
    "\n",
    "import anndata as ad\n",
    "import scvi\n",
    "from regvelo import REGVELOVI\n",
    "\n",
    "from rgv_tools import DATA_DIR\n",
    "from rgv_tools.benchmarking import (\n",
    "    set_output,\n",
    ")\n",
    "\n",
    "from itertools import product, permutations\n",
    "from operator import pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeae04a-6f43-4902-a5b4-2f131013c2d1",
   "metadata": {},
   "source": [
    "## General setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2251dc-36ad-4902-aeff-a0cd91c295a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "scvi.settings.seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5e0bd-7d46-4301-a6c1-2fec79ae8638",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b2a2ad-4c83-4bee-9fc6-2d68dbdce7cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET = \"mHSPC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ada6221f-9045-4275-a8d2-42ba4bf5622d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVE_DATA = True\n",
    "if SAVE_DATA:\n",
    "    (DATA_DIR / DATASET / \"results\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca567fed-8544-45c0-a88c-7cb4ac9d9506",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8229c061-2de6-4777-aee8-af46cc024f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unsigned(\n",
    "        true_edges: pd.DataFrame,\n",
    "        pred_edges: pd.DataFrame,\n",
    "        type: str = \"alledges\"\n",
    "    ) -> tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        Compare true vs predicted edges (unsigned) and compute precision/recall metrics.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (eprec, erec, eprec_ratio)\n",
    "        \"\"\"\n",
    "        true_edges_copy = true_edges.copy()\n",
    "        pred_edges_copy = pred_edges.copy()\n",
    "\n",
    "        # Drop self-edges and duplicates\n",
    "        true_edges_copy = true_edges_copy.loc[(true_edges_copy['Gene1'] != true_edges_copy['Gene2'])]\n",
    "        true_edges_copy.drop_duplicates(keep='first', inplace=True)\n",
    "        true_edges_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        pred_edges_copy = pred_edges_copy.loc[(pred_edges_copy['Gene1'] != pred_edges_copy['Gene2'])]\n",
    "        pred_edges_copy.drop_duplicates(keep='first', inplace=True)\n",
    "        pred_edges_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Get a list of all possible TF to gene interactions \n",
    "        unique_nodes = np.unique(true_edges_copy.loc[:, ['Gene1', 'Gene2']])\n",
    "        possible_edges_all = set(product(set(true_edges_copy.Gene1), set(unique_nodes)))\n",
    "\n",
    "        # Get a list of all possible interactions \n",
    "        possible_edges_no_self = set(permutations(unique_nodes, r=2))\n",
    "\n",
    "        # Find intersection of above lists to ignore self edges\n",
    "        possible_edges = possible_edges_all.intersection(possible_edges_no_self)\n",
    "\n",
    "        true_edges_dict = {'|'.join(p): 0 for p in possible_edges}\n",
    "\n",
    "        true_edges_str = true_edges_copy['Gene1'] + \"|\" + true_edges_copy['Gene2']\n",
    "        true_edges_str = true_edges_str[true_edges_str.isin(true_edges_dict)]\n",
    "        n_edges = len(true_edges_str)\n",
    "\n",
    "        pred_edges_copy['Edges'] = pred_edges_copy['Gene1'] + \"|\" + pred_edges_copy['Gene2']\n",
    "        pred_edges_copy = pred_edges_copy[pred_edges_copy['Edges'].isin(true_edges_dict)]\n",
    "        pred_edges_copy_copy = pred_edges_copy.copy()\n",
    "\n",
    "        if not pred_edges_copy.shape[0] == 0:\n",
    "            pred_edges_copy.loc[:, \"EdgeWeight\"] = pred_edges_copy.EdgeWeight.round(6).abs()\n",
    "            pred_edges_copy.sort_values(by=\"EdgeWeight\", ascending=False, inplace=True)\n",
    "\n",
    "            maxk = min(pred_edges_copy.shape[0], n_edges)\n",
    "            edge_weight_topk = pred_edges_copy.iloc[maxk-1].EdgeWeight\n",
    "\n",
    "            nnz_min = np.nanmin(pred_edges_copy.EdgeWeight.replace(0, np.nan).values)\n",
    "            best_val = max(nnz_min, edge_weight_topk)\n",
    "\n",
    "            newDF = pred_edges_copy.loc[(pred_edges_copy['EdgeWeight'] >= best_val)]\n",
    "            rank = set(newDF['Gene1'] + \"|\" + newDF['Gene2'])\n",
    "\n",
    "            intersectionSet = rank.intersection(true_edges_str)\n",
    "            eprec = len(intersectionSet) / len(rank)\n",
    "            erec = len(intersectionSet) / len(true_edges_str)\n",
    "\n",
    "            random_eprec = n_edges / len(true_edges_dict)\n",
    "            eprec_ratio = eprec / random_eprec\n",
    "        else:\n",
    "            eprec = 1.0\n",
    "            erec = 1.0\n",
    "            eprec_ratio = 1.0\n",
    "\n",
    "        print(\"EPR: \" + str(eprec_ratio))\n",
    "        return eprec, erec, eprec_ratio\n",
    "\n",
    "\n",
    "def calculate_auroc(\n",
    "        inferred_scores_df: pd.DataFrame,\n",
    "        ground_truth_df: pd.DataFrame\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate AUROC comparing inferred edge scores against ground truth.\n",
    "\n",
    "        Returns:\n",
    "            float: AUROC score.\n",
    "        \"\"\"\n",
    "        ground_truth_set = set(zip(ground_truth_df['Gene1'], ground_truth_df['Gene2']))\n",
    "\n",
    "        inferred_scores_df['label'] = inferred_scores_df.apply(\n",
    "            lambda row: (row['Gene1'], row['Gene2']) in ground_truth_set, axis=1\n",
    "        ).astype(int)\n",
    "\n",
    "        y_true = inferred_scores_df['label']\n",
    "        y_scores = inferred_scores_df['EdgeWeight']\n",
    "\n",
    "        auroc = roc_auc_score(y_true, y_scores)\n",
    "        return auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea1a8d-c09e-419b-9081-206acb081c13",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae45641b-d451-450f-a027-8692d94b87c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(DATA_DIR / DATASET / \"processed\" / \"mHSC_ExpressionData.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55949eab-8169-434b-895b-1d84d1d86a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TF = pd.read_csv(DATA_DIR / DATASET / \"raw\" / \"mouse-tfs.csv\")\n",
    "TF = [i[0].upper() + i[1:].lower() for i in TF[\"TF\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c73322b7-701e-4667-bec1-24e3242e85f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TF = np.array(TF)[[i in adata.var_names for i in TF]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "409b9464-031c-4c81-b997-2ccf5e34a9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankrd22', 'Ankrd7', 'Arntl2', 'Batf3', 'Bcl11b', 'Bmp6', 'Btg2',\n",
       "       'Chd7', 'Ciita', 'Cnot6l', 'Creb5', 'Csrp3', 'Ctr9', 'Ebf1',\n",
       "       'Egr2', 'Esr1', 'Ets1', 'Etv6', 'Eya1', 'Eya2', 'Eya4', 'Fos',\n",
       "       'Fosb', 'Gata1', 'Gata2', 'Gata3', 'Gfi1', 'Gfi1b', 'Glis3', 'Hlf',\n",
       "       'Hoxa9', 'Hspb1', 'Id2', 'Id3', 'Ifi204', 'Ikzf1', 'Ikzf3', 'Il10',\n",
       "       'Irf4', 'Irf8', 'Isl1', 'Klf1', 'Klf6', 'Kpna2', 'Ldb2', 'Lef1',\n",
       "       'Lmo4', 'Maf', 'Mapk11', 'Mecom', 'Mef2c', 'Meis1', 'Mllt3',\n",
       "       'Mmp9', 'Myb', 'Myc', 'Mycn', 'Nfatc2', 'Nfia', 'Nfil3', 'Nfkbiz',\n",
       "       'Nr1h4', 'Pax5', 'Pgr', 'Pou2af1', 'Prdm1', 'Rad54b', 'Rapgef3',\n",
       "       'Relb', 'Rora', 'Runx1t1', 'Satb1', 'Setbp1', 'Sla2', 'Smarca4',\n",
       "       'Spib', 'Stat3', 'Stat4', 'Tox2', 'Trib3', 'Trps1', 'Xbp1',\n",
       "       'Zbtb16', 'Zbtb20', 'Zbtb38', 'Zfp354a'], dtype='<U12')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c724e9a-c3e5-4bb3-955d-55f615eed14b",
   "metadata": {},
   "source": [
    "## Velocity pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a7fc05d-3213-4018-8f7e-e44007d22cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/icb/weixu.wang/miniconda3/envs/regvelo_test/li ...\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/icb/weixu.wang/miniconda3/envs/regvelo_test/li ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/icb/weixu.wang/miniconda3/envs/regvelo_test/li ...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601ad9eb2c9f4cc2a8cfa8b5d7ec342f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: -2721.169. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/icb/weixu.wang/miniconda3/envs/regvelo_test/li ...\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/icb/weixu.wang/miniconda3/envs/regvelo_test/li ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/icb/weixu.wang/miniconda3/envs/regvelo_test/li ...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36d6755f9814269bce4e1907d647188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: -2762.707. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/icb/weixu.wang/miniconda3/envs/regvelo_test/li ...\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/icb/weixu.wang/miniconda3/envs/regvelo_test/li ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/icb/weixu.wang/miniconda3/envs/regvelo_test/li ...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075a3c421b6343e69c53dcf41fc92dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W = torch.ones([adata.n_vars, adata.n_vars])\n",
    "vae_list = []\n",
    "\n",
    "for nrun in range(3):\n",
    "    REGVELOVI.setup_anndata(adata, spliced_layer=\"Ms\", unspliced_layer=\"Mu\")\n",
    "    vae = REGVELOVI(adata, W=W, regulators = TF)\n",
    "    vae.train()\n",
    "    vae_list.append(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c4b25bc-3af2-4f96-8b62-d05d0afc62a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPR: 1.1386958157171931\n",
      "EPR: 1.145426793837005\n",
      "EPR: 1.1243054487024222\n"
     ]
    }
   ],
   "source": [
    "EPR_score = []\n",
    "AUC_score = []\n",
    "\n",
    "for nrun in range(3):\n",
    "    vae = vae_list[nrun]\n",
    "    grn_estimate = vae.module.v_encoder.GRN_Jacobian(torch.tensor(adata.layers[\"Ms\"]).to(\"cuda:0\"))\n",
    "    grn_estimate = grn_estimate.cpu().detach().numpy()\n",
    "    grn_estimate = np.abs(grn_estimate)\n",
    "    grn_estimate = pd.DataFrame(grn_estimate,index = adata.var_names.tolist(),columns = adata.var_names.tolist())\n",
    "    grn_estimate = grn_estimate.loc[:,TF].copy()\n",
    "\n",
    "    grn = pd.DataFrame(grn_estimate.stack()).reset_index()\n",
    "    grn.columns = ['Gene2','Gene1','EdgeWeight']\n",
    "    result = grn[['Gene1', 'Gene2', 'EdgeWeight']].sort_values(\n",
    "            by='EdgeWeight', ascending=False\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "    gt = pd.read_csv(DATA_DIR / DATASET / \"raw\" / \"mHSC-ChIP-seq-network.csv\")\n",
    "    gt[\"Gene1\"] =  [i[0].upper() + i[1:].lower() for i in gt[\"Gene1\"].tolist()]\n",
    "    gt[\"Gene2\"] =  [i[0].upper() + i[1:].lower() for i in gt[\"Gene2\"].tolist()]\n",
    "    gt = gt.loc[[i in TF for i in gt[\"Gene1\"]],:]\n",
    "    gt = gt.loc[[i in adata.var_names for i in gt[\"Gene2\"]],:]\n",
    "    _,_,epr = unsigned(gt,result)\n",
    "    EPR_score.append(epr)\n",
    "    AUC_score.append(calculate_auroc(result,gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac522b-af9a-4ffb-b542-14ef7cff0fda",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b83e35b-602f-4e84-978e-64387d73658f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\"EPR\":EPR_score,\n",
    "                          \"AUC\":AUC_score,\n",
    "                          \"Method\":[\"regvelo\"]*3})\n",
    "\n",
    "if SAVE_DATA:\n",
    "    result_df.to_csv(DATA_DIR / DATASET / \"results\" / \"GRN_benchmark_rgv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41895524-818a-4133-ae2e-98f1d204f2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:regvelo_test]",
   "language": "python",
   "name": "conda-env-regvelo_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
