{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFvelo benchmark on cell cycle data\n",
    "\n",
    "Notebook benchmarks velocity, latent time inference, and cross boundary correctness using TFvelo on cell cycle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/99 TMEM176A\n",
      "0/99 TMEM176A FINISHED with n_TFs: 26\n",
      "Processing 1/99 CX3CL1\n",
      "1/99 CX3CL1 FINISHED with n_TFs: 26\n",
      "Processing 2/99 ETV1\n",
      "2/99 ETV1 FINISHED with n_TFs: 25\n",
      "Processing 3/99 DBF4\n",
      "3/99 DBF4 FINISHED with n_TFs: 26\n",
      "Processing 4/99 MYLIP\n",
      "4/99 MYLIP FINISHED with n_TFs: 26\n",
      "Processing 5/99 ETV7\n",
      "5/99 ETV7 FINISHED with n_TFs: 25\n",
      "Processing 6/99 DCN\n",
      "6/99 DCN FINISHED with n_TFs: 26\n",
      "Processing 7/99 GPRC5A\n",
      "7/99 GPRC5A FINISHED with n_TFs: 26\n",
      "Processing 8/99 CYP24A1\n",
      "8/99 CYP24A1 FINISHED with n_TFs: 26\n",
      "WARNING: 9/99 HGF not recoverable due to insufficient samples.\n",
      "Processing 10/99 PLEKHB1\n",
      "10/99 PLEKHB1 FINISHED with n_TFs: 26\n",
      "Processing 11/99 SLAMF7\n",
      "11/99 SLAMF7 FINISHED with n_TFs: 26\n",
      "Processing 12/99 LRRC7\n",
      "12/99 LRRC7 FINISHED with n_TFs: 26\n",
      "Processing 13/99 TLL1\n",
      "13/99 TLL1 FINISHED with n_TFs: 26\n",
      "Processing 14/99 SPDL1\n",
      "14/99 SPDL1 FINISHED with n_TFs: 26\n",
      "Processing 15/99 FAM214A\n",
      "15/99 FAM214A FINISHED with n_TFs: 26\n",
      "Processing 16/99 ANO2\n",
      "16/99 ANO2 FINISHED with n_TFs: 26\n",
      "Processing 17/99 CELF2\n",
      "17/99 CELF2 FINISHED with n_TFs: 26\n",
      "Processing 18/99 ADAMTS6\n",
      "18/99 ADAMTS6 FINISHED with n_TFs: 26\n",
      "Processing 19/99 CLPTM1L\n",
      "19/99 CLPTM1L FINISHED with n_TFs: 26\n",
      "Processing 20/99 TRAF1\n",
      "20/99 TRAF1 FINISHED with n_TFs: 26\n",
      "Processing 21/99 NDC1\n",
      "21/99 NDC1 FINISHED with n_TFs: 26\n",
      "Processing 22/99 SLC2A3\n",
      "22/99 SLC2A3 FINISHED with n_TFs: 26\n",
      "Processing 23/99 GLP2R\n",
      "23/99 GLP2R FINISHED with n_TFs: 26\n",
      "Processing 24/99 ASPM\n",
      "24/99 ASPM FINISHED with n_TFs: 26\n",
      "Processing 25/99 MAOB\n",
      "25/99 MAOB FINISHED with n_TFs: 26\n",
      "Processing 26/99 TRIB2\n",
      "26/99 TRIB2 FINISHED with n_TFs: 26\n",
      "Processing 27/99 SEMA3A\n",
      "27/99 SEMA3A FINISHED with n_TFs: 26\n",
      "Processing 28/99 GTSE1\n",
      "28/99 GTSE1 FINISHED with n_TFs: 26\n",
      "Processing 29/99 SEMA3C\n",
      "29/99 SEMA3C FINISHED with n_TFs: 26\n",
      "Processing 30/99 UNG\n",
      "30/99 UNG FINISHED with n_TFs: 26\n",
      "Processing 31/99 MAP2\n",
      "31/99 MAP2 FINISHED with n_TFs: 26\n",
      "Processing 32/99 FAP\n",
      "32/99 FAP FINISHED with n_TFs: 26\n",
      "Processing 33/99 EDN1\n",
      "33/99 EDN1 FINISHED with n_TFs: 26\n",
      "Processing 34/99 KIF22\n",
      "34/99 KIF22 FINISHED with n_TFs: 26\n",
      "Processing 35/99 NDC80\n",
      "35/99 NDC80 FINISHED with n_TFs: 26\n",
      "Processing 36/99 SMAP2\n",
      "36/99 SMAP2 FINISHED with n_TFs: 26\n",
      "Processing 37/99 SSH1\n",
      "37/99 SSH1 FINISHED with n_TFs: 26\n",
      "Processing 38/99 AKR1B1\n",
      "38/99 AKR1B1 FINISHED with n_TFs: 26\n",
      "Processing 39/99 FTL\n",
      "39/99 FTL FINISHED with n_TFs: 26\n",
      "Processing 40/99 AURKA\n",
      "40/99 AURKA FINISHED with n_TFs: 26\n",
      "Processing 41/99 TPX2\n",
      "41/99 TPX2 FINISHED with n_TFs: 26\n",
      "Processing 42/99 ARHGAP28\n",
      "42/99 ARHGAP28 FINISHED with n_TFs: 26\n",
      "Processing 43/99 HEPH\n",
      "43/99 HEPH FINISHED with n_TFs: 26\n",
      "Processing 44/99 CPA1\n",
      "44/99 CPA1 FINISHED with n_TFs: 26\n",
      "Processing 45/99 TGFB2\n",
      "45/99 TGFB2 FINISHED with n_TFs: 26\n",
      "Processing 46/99 CDC6\n",
      "46/99 CDC6 FINISHED with n_TFs: 26\n",
      "Processing 47/99 CREM\n",
      "47/99 CREM FINISHED with n_TFs: 25\n",
      "Processing 48/99 DSP\n",
      "48/99 DSP FINISHED with n_TFs: 26\n",
      "Processing 49/99 NRP1\n",
      "49/99 NRP1 FINISHED with n_TFs: 26\n",
      "Processing 50/99 PIK3IP1\n",
      "50/99 PIK3IP1 FINISHED with n_TFs: 26\n",
      "Processing 51/99 HMOX1\n",
      "51/99 HMOX1 FINISHED with n_TFs: 26\n",
      "Processing 52/99 PDGFB\n",
      "52/99 PDGFB FINISHED with n_TFs: 26\n",
      "Processing 53/99 KCNK10\n",
      "53/99 KCNK10 FINISHED with n_TFs: 26\n",
      "Processing 54/99 BIRC7\n",
      "54/99 BIRC7 FINISHED with n_TFs: 26\n",
      "Processing 55/99 TRIB3\n",
      "55/99 TRIB3 FINISHED with n_TFs: 26\n",
      "Processing 56/99 FAM83D\n",
      "56/99 FAM83D FINISHED with n_TFs: 26\n",
      "Processing 57/99 KLF8\n",
      "57/99 KLF8 FINISHED with n_TFs: 25\n",
      "Processing 58/99 FGF9\n",
      "58/99 FGF9 FINISHED with n_TFs: 26\n",
      "Processing 59/99 MSLN\n",
      "59/99 MSLN FINISHED with n_TFs: 26\n",
      "Processing 60/99 NDRG4\n",
      "60/99 NDRG4 FINISHED with n_TFs: 26\n",
      "WARNING: 61/99 PRSS33 not recoverable due to insufficient samples.\n",
      "Processing 62/99 BMF\n",
      "62/99 BMF FINISHED with n_TFs: 26\n",
      "Processing 63/99 EYA1\n",
      "63/99 EYA1 FINISHED with n_TFs: 26\n",
      "Processing 64/99 KCNA7\n",
      "64/99 KCNA7 FINISHED with n_TFs: 26\n",
      "Processing 65/99 TLE6\n",
      "65/99 TLE6 FINISHED with n_TFs: 26\n",
      "Processing 66/99 CCNE1\n",
      "66/99 CCNE1 FINISHED with n_TFs: 26\n",
      "Processing 67/99 SLC1A5\n",
      "67/99 SLC1A5 FINISHED with n_TFs: 26\n",
      "Processing 68/99 PLA2G4C\n",
      "68/99 PLA2G4C FINISHED with n_TFs: 26\n",
      "Processing 69/99 ITGB8\n",
      "69/99 ITGB8 FINISHED with n_TFs: 26\n",
      "Processing 70/99 CAV1\n",
      "70/99 CAV1 FINISHED with n_TFs: 26\n",
      "Processing 71/99 GARS\n",
      "71/99 GARS FINISHED with n_TFs: 26\n",
      "Processing 72/99 SERPINE1\n",
      "72/99 SERPINE1 FINISHED with n_TFs: 26\n",
      "WARNING: 73/99 AGR2 not recoverable due to insufficient samples.\n",
      "Processing 74/99 TMEM176B\n",
      "74/99 TMEM176B FINISHED with n_TFs: 26\n",
      "Processing 75/99 PDLIM1\n",
      "75/99 PDLIM1 FINISHED with n_TFs: 26\n",
      "Processing 76/99 UNC5B\n",
      "76/99 UNC5B FINISHED with n_TFs: 26\n",
      "Processing 77/99 DNAJC12\n",
      "77/99 DNAJC12 FINISHED with n_TFs: 26\n",
      "Processing 78/99 P2RX1\n",
      "78/99 P2RX1 FINISHED with n_TFs: 26\n",
      "Processing 79/99 AREG\n",
      "79/99 AREG FINISHED with n_TFs: 26\n",
      "Processing 80/99 RPL34\n",
      "80/99 RPL34 FINISHED with n_TFs: 26\n",
      "Processing 81/99 CTSC\n",
      "81/99 CTSC FINISHED with n_TFs: 26\n",
      "Processing 82/99 HPX\n",
      "82/99 HPX FINISHED with n_TFs: 26\n",
      "Processing 83/99 SOX6\n",
      "83/99 SOX6 FINISHED with n_TFs: 25\n",
      "Processing 84/99 PRMT8\n",
      "84/99 PRMT8 FINISHED with n_TFs: 26\n",
      "Processing 85/99 LTBR\n",
      "85/99 LTBR FINISHED with n_TFs: 26\n",
      "Processing 86/99 MCM3\n",
      "86/99 MCM3 FINISHED with n_TFs: 26\n",
      "Processing 87/99 PTP4A1\n",
      "87/99 PTP4A1 FINISHED with n_TFs: 26\n",
      "Processing 88/99 LAMA4\n",
      "88/99 LAMA4 FINISHED with n_TFs: 26\n",
      "Processing 89/99 ARRDC3\n",
      "89/99 ARRDC3 FINISHED with n_TFs: 26\n",
      "Processing 90/99 DPYSL3\n",
      "90/99 DPYSL3 FINISHED with n_TFs: 26\n",
      "Processing 91/99 STC2\n",
      "91/99 STC2 FINISHED with n_TFs: 26\n",
      "Processing 92/99 ECT2\n",
      "92/99 ECT2 FINISHED with n_TFs: 26\n",
      "Processing 93/99 KLHL24\n",
      "93/99 KLHL24 FINISHED with n_TFs: 26\n",
      "Processing 94/99 IFIH1\n",
      "94/99 IFIH1 FINISHED with n_TFs: 26\n",
      "Processing 95/99 FN1\n",
      "95/99 FN1 FINISHED with n_TFs: 26\n",
      "Processing 96/99 GLS\n",
      "96/99 GLS FINISHED with n_TFs: 26\n",
      "Processing 97/99 IGFBP5\n",
      "97/99 IGFBP5 FINISHED with n_TFs: 26\n",
      "Processing 98/99 ID2\n",
      "98/99 ID2 FINISHED with n_TFs: 26\n"
     ]
    }
   ],
   "source": [
    "import TFvelo as TFv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import anndata as ad\n",
    "import scvelo as scv\n",
    "from cellrank.kernels import VelocityKernel\n",
    "\n",
    "from rgv_tools import DATA_DIR\n",
    "from rgv_tools.benchmarking import get_grn_auroc_cc, get_time_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scv.settings.verbosity = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"cell_cycle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_TRANSITIONS = [(\"G1\", \"S\"), (\"S\", \"G2M\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DATA = True\n",
    "if SAVE_DATA:\n",
    "    (DATA_DIR / DATASET / \"results\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1146 × 395\n",
       "    obs: 'phase', 'fucci_time', 'initial_size_unspliced', 'initial_size_spliced', 'initial_size', 'n_counts'\n",
       "    var: 'ensum_id', 'gene_count_corr', 'means', 'dispersions', 'dispersions_norm', 'highly_variable', 'velocity_gamma', 'velocity_qreg_ratio', 'velocity_r2', 'velocity_genes'\n",
       "    uns: 'log1p', 'neighbors', 'pca', 'umap', 'velocity_params'\n",
       "    obsm: 'X_pca', 'X_umap'\n",
       "    varm: 'PCs', 'true_skeleton'\n",
       "    layers: 'Ms', 'Mu', 'spliced', 'total', 'unspliced', 'velocity'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = ad.io.read_h5ad(DATA_DIR / DATASET / \"processed\" / \"adata_processed.h5ad\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity pipeline\n",
    "\n",
    "TFvelo preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"spliced\" in adata.layers:\n",
    "    adata.layers[\"total\"] = adata.layers[\"spliced\"].todense() + adata.layers[\"unspliced\"].todense()\n",
    "elif \"new\" in adata.layers:\n",
    "    adata.layers[\"total\"] = np.array(adata.layers[\"total\"].todense())\n",
    "else:\n",
    "    adata.layers[\"total\"] = adata.X\n",
    "adata.layers[\"total_raw\"] = adata.layers[\"total\"].copy()\n",
    "n_cells, n_genes = adata.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFv.pp.moments(adata, n_pcs=30)\n",
    "\n",
    "TFv.pp.get_TFs(adata, databases=\"all\")\n",
    "adata.uns[\"genes_pp\"] = np.array(adata.var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing moments based on connectivities\n",
      "    finished (0:00:00) --> added \n",
      "    'M_total', moments of total abundances (adata.layers)\n",
      "Get TFs according to all\n",
      "max_n_TF: 26\n",
      "mean_n_TF: 25.934177215189873\n",
      "gene num of 0 TF: 0\n",
      "total num of TFs: 26\n",
      "recovering dynamics (using 4/112 cores)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168ac2702349496b8a6694dac6a3add5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?gene/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/weixu.wang/miniconda3/envs/regvelo_test/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:31:24) --> added \n",
      "    'fit_pars', fitted parameters for splicing dynamics (adata.var)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFv.tl.recover_dynamics(\n",
    "    adata,\n",
    "    n_jobs=4,\n",
    "    max_iter=20,\n",
    "    var_names=\"all\",\n",
    "    WX_method=\"lsq_linear\",\n",
    "    WX_thres=20,\n",
    "    n_top_genes=2000,\n",
    "    fit_scaling=True,\n",
    "    use_raw=0,\n",
    "    init_weight_method=\"correlation\",\n",
    "    n_time_points=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata.layers[\"fit_t\"] = np.nan_to_num(adata.layers[\"fit_t\"], nan=0)\n",
    "time_correlation = [\n",
    "    get_time_correlation(ground_truth=adata.obs[\"fucci_time\"], estimated=adata.layers[\"fit_t\"].mean(axis=1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grn_estimate = pd.DataFrame(0, index=adata.var_names, columns=adata.var_names)\n",
    "grn_estimate.loc[:, adata.uns[\"all_TFs\"]] = adata.varm[\"fit_weights_final\"]\n",
    "grn_estimate = np.array(grn_estimate)\n",
    "grn_correlation = [\n",
    "    get_grn_auroc_cc(ground_truth=adata.varm[\"true_skeleton\"].toarray(), estimated=np.abs(grn_estimate).T)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing velocity graph (using 1/112 cores)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73511b2114646ed8f21adb1af8e08a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1146 [00:00<?, ?cells/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:01) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "--> added 'velocity_length' (adata.obs)\n",
      "--> added 'velocity_confidence' (adata.obs)\n",
      "--> added 'velocity_confidence_transition' (adata.obs)\n"
     ]
    }
   ],
   "source": [
    "scv.tl.velocity_graph(adata, vkey=\"velocity\", n_jobs=1)\n",
    "scv.tl.velocity_confidence(adata, vkey=\"velocity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-boundary correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ca945a085e4d9b9e07027306309a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1146 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b38847b0fac405eac8a3eae9170de13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1146 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vk = VelocityKernel(adata, vkey=\"velocity\", xkey=\"M_total\").compute_transition_matrix()\n",
    "\n",
    "cluster_key = \"phase\"\n",
    "rep = \"X_pca\"\n",
    "\n",
    "score_df = []\n",
    "for source, target in STATE_TRANSITIONS:\n",
    "    cbc = vk.cbc(source=source, target=target, cluster_key=cluster_key, rep=rep)\n",
    "\n",
    "    score_df.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"State transition\": [f\"{source} - {target}\"] * len(cbc),\n",
    "                \"CBC\": cbc,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "score_df = pd.concat(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_DATA:\n",
    "    pd.DataFrame({\"time\": time_correlation}, index=adata.obs_names).to_parquet(\n",
    "        path=DATA_DIR / DATASET / \"results\" / \"tfvelo_correlation.parquet\"\n",
    "    )\n",
    "    pd.DataFrame({\"grn\": grn_correlation}).to_parquet(\n",
    "        path=DATA_DIR / DATASET / \"results\" / \"tfvelo_grn_correlation.parquet\"\n",
    "    )\n",
    "    adata.obs[[\"velocity_confidence\"]].to_parquet(path=DATA_DIR / DATASET / \"results\" / \"tfvelo_confidence.parquet\")\n",
    "    score_df.to_parquet(path=DATA_DIR / DATASET / \"results\" / \"tfvelo_cbc.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:regvelo_test]",
   "language": "python",
   "name": "conda-env-regvelo_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
